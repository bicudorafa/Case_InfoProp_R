method = "lm",
trControl = control,
metric = 'RMSE')
model1
model2
control_rfe <- rfeControl(functions=lmFuncs, method="cv", number=10)
results <- rfe(price ~ ., data = train_preproc, sizes=c(1:15), rfeControl=control_rfe)
varImp(results, scale=FALSE)
plot(results, type=c("g", "o"))
model2 <- train(price ~ garage_coerc5,
data = train_preproc,
method = "lm",
trControl = control,
metric = 'RMSE')
model2 <- train(price ~
area +
garage_coerc +
valores_condo+
rooms_coerc +
anuncio_condo +
valores_agente +
valores_rua,
data = train_preproc,
method = "lm",
trControl = control,
metric = 'RMSE')
plot(varImp(model2, scale=FALSE))
model2
# Create model_list
model_list <- list(BENCH = model1, FE_FS = model2)
# Pass model_list to resamples(): resamples
resamples <- resamples(model_list)
# Create bwplot
dotplot(resamples, metric = 'ROC')
# Create bwplot
dotplot(resamples)
# Create bwplot
dotplot(resamples, metric = 'RMSE')
model2 <- train(price ~ .,
data = train_preproc,
method = "lm",
trControl = control,
metric = 'RMSE')
model2
model1
# Create model_list
model_list <- list(BENCH = model1, FE_FS = model2)
# Pass model_list to resamples(): resamples
resamples <- resamples(model_list)
# Summarize the results
#summary(resamples)
# Create bwplot
dotplot(resamples, metric = 'RMSE')
# Create bwplot
dotplot(resamples, metric = 'R')
# Create bwplot
dotplot(resamples)
pred1 <- predict(model1, test_preproc_bench)
pred2 <- predict(model2, test_preproc)
test_Score1 <-data.frame(obs = test_preproc_bench$price, pred= pred1)
test_Score2 <-data.frame(obs = test_preproc$price, pred= pred2)
defaultSummary(test_Score1)
######
# score modelo
pred1 <- predict(model1, test_preproc_bench)
pred2 <- predict(model2, test_preproc)
test_Score2 <-data.frame(obs = test_preproc$price, pred= pred2)
defaultSummary(test_Score2)
######
# score modelo
pred1 <- predict(model1, test_preproc_bench)
######
# score modelo
pred1 <- predict(model1, test_preproc_bench, type="response", se.fit=FALSE)
######
# score modelo
pred1 <- predict(model1, test_preproc_bench, se.fit=FALSE)
######
# score modelo
pred1 <- predict(model1, test_preproc_bench, type="response", se.fit=FALSE)
names(imoveis_final)
# Controle para todos os modelos
control <- trainControl(method="cv", number=10)
# modelo com as originais
model1 <- train(price ~
area +
condominium_fee +
iptu +
rooms_coerc +
bathrooms_coerc +
garage_coerc + ,
data = train_preproc,
method = "lm",
trControl = control,
metric = 'RMSE')
model1 <- train(price ~
area +
condominium_fee +
iptu +
rooms_coerc +
bathrooms_coerc +
garage_coerc,
data = train_preproc,
method = "lm",
trControl = control,
metric = 'RMSE')
model1
model2
plot(varImp(model2, scale=FALSE))
model_list <- list(Originais = model1, Originais_eNovas = model2)
resamples <- resamples(model_list)
dotplot(resamples)
dotplot(resamples, metric = 'RMSE')
pred1 <- predict(model1, test_preproc)
pred2 <- predict(model2, test_preproc)
test_Score1 <-data.frame(obs = test_preproc_bench$price, pred= pred1)
test_Score2 <-data.frame(obs = test_preproc$price, pred= pred2)
test_Score1 <-data.frame(obs = test_preproc$price, pred= pred1)
test_Score2 <-data.frame(obs = test_preproc$price, pred= pred2)
defaultSummary(test_Score1)
defaultSummary(test_Score2)
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
install.packages("drat", repos="https://cran.rstudio.com")
install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
require(xgboost)
data(agaricus.train, package='xgboost')
View(agaricus.train)
str(agaricus.train)
bstSparse <- xgboost(data = train$data, label = train$label, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
options (error = browser)
train <- agaricus.train
bstSparse <- xgboost(data = train$data, label = train$label, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
install.packages('vtreat')
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
imoveis_clean <- imoveis_clean %>% filter(!(price == 18000))
var_t <- list(imoveis_clean_rua %>% arrange(desc(total_a)),
imoveis_clean_condominio %>% arrange(desc(total_a)),
imoveis_clean_agent %>% arrange(desc(total_a)))
plots_total <- list()
for (i in 1:length(var_t)){
plots_total[[i]] <- ggplot(var_t[[i]], aes(x = factor(var_t[[i]][[1]], levels = var_t[[i]][[1]]),
y = total_a)) +
geom_bar(stat="identity", width=.5) +
coord_flip() +
labs(title=paste('Anúncios x ', names(var_t[[i]])[[1]]),
x = names(names(var_t[[i]])[[1]]),
y = 'Anúncios')
print(plots_total[[i]])
}
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage)
View(imoveis_clean)
# agregação dos valores para não causar overfitting pela baixa quantidade de valores
roomsBathGarage <- imoveis_clean %>%
select(c(rooms, bathrooms, garage, property_d)) %>%
mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
garage_coerc = ifelse(garage > 5, 5, garage))
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d'))
options (error = browser)
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
a
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo)
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente)
View(imoveis_final)
roomsBathGarage <- imoveis_clean %>%
select(c(rooms, bathrooms, garage, property_d)) %>%
mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
garage_coerc = ifelse(garage > 5, 5, garage)) %>%
select(-c(rooms, bathrooms, garage, property_d))
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d'))
View(roomsBathGarage)
roomsBathGarage <- imoveis_clean %>%
select(c(rooms, bathrooms, garage, property_d)) %>%
mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
garage_coerc = ifelse(garage > 5, 5, garage)) %>%
select(-c(rooms, bathrooms, garage))
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
View(imoveis_final)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
#Carregando pacote necessario e iniciando seed do projeto
library(caret)
library(vtreat)
library(xgboost)
set.seed(666)
sample <- createDataPartition(imoveis_final$price, times = 1, list = F, p = .7)
train_sample <- imoveis_final[sample, ]
test_sample <- imoveis_final[-sample, ]
View(imoveis_final)
## Pre processamento usando vtreat
X_train <- train_sample[-1]
View(X_train)
y_trains <- train_sample[1]
vars_input <- names(X_train)
treatplan <- designTreatmentsZ(X_train, vars)
vars_input <- names(X_train)
treatplan <- designTreatmentsZ(X_train, vars_input)
summary(imoveis_final)
View(imoveis)
library(dplyr)
library(stringr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(tidyr)
library(caret)
library(vtreat)
library(xgboost)
set.seed(666)
# funcao para transformar variaveis em fact
toFactor <- function(df, features) {
for (feature in features) {
df[[feature]] <- factor(df[[feature]], exclude = NULL)
# exclude é importantíssimo pra considerar NA como classe
}
return(df)
}
# dfs em factor
train_fact <- toFactor(train_sample, c('rooms_coerc', 'bathrooms_coerc','garage_coerc'))
test_fact <- toFactor(test_sample, c('rooms_coerc', 'bathrooms_coerc','garage_coerc'))
X_train <- train_fact[-1]
y_trains <- train_fact[1]
vars_input <- names(X_train)
treatplan <- designTreatmentsZ(X_train, vars_input)
treatplan %>%
use_series(scoreFrame)
treatplan %>%
magrittr::use_series(scoreFrame)
scoreFrame <- treatplan %>%
magrittr::use_series(scoreFrame) %>% # forma dplyr de fazer subsetting "$"
select(varName, origName, code)
scoreFrame %>%
filter(code %in% c('clean', 'lev')) %>%
magrittr::use_series(varName)
y_train <- train_fact[1]
# obtenção do string vector somente com as variáveis requeridas
novas_vars <- scoreFrame %>%
filter(code %in% c('clean', 'lev')) %>%
magrittr::use_series(varName)
novas_vars
X_test <- test_fact[-1]
y_test <- test_fact[1]
# dfs tratados
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars)
X_test_treat <- prepare(treatplan, X_test, varRestriction = novas_vars)
View(X_train_treat)
typeof(X_test_treat)
# Modelo usando xgboost
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 100, # n de rounds
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.3, # taxa de aprendizagem
max_depth = 6, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
# Modelo usando xgboost
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 100, # n de rounds
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.3, # taxa de aprendizagem
max_depth = 6, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
options (error = browser)
y_train <- train_fact$price
# Modelo usando xgboost
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 100, # n de rounds
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.3, # taxa de aprendizagem
max_depth = 6, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
y_test <- test_fact$price
# Determine and print how many trees minimize training and test error
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))   # find the index of min(test_rmse_mean)
# Determine and print how many trees minimize training and test error
xgb_cv$evaluation_log %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))   # find the index of min(test_rmse_mean)
xgb_cv
View(X_train)
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))   # find the index of min(test_rmse_mean)
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
select(ntrees.test)
nrounds_ideal <- xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
select(ntrees.test)
View(nrounds_ideal)
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
as.numeric()
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
select(ntrees.test) %>% as.numeric()
nrounds_ideal <- xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
select(ntrees.test) %>% as.numeric()
nrounds_ideal <- xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
nrounds_ideal
# Modelo
imoveis_xgb <- xgboost(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 30,
objective = 'reg:linear',
eta = 0.3,
depth = 6,
verbose = 0
)
View(imoveis_xgb)
summary(imoveis_xgb)
# Make predictions
X_test_treat$pred <- predict(imoveis_xgb, as.matrix(X_test_treat))
ggplot(X_test_treat, aes(x = pred, y = price)) +
geom_point() +
geom_abline()
X_test_treat <- prepare(treatplan, X_test, varRestriction = novas_vars)
# Make predictions
y_test$pred <- predict(imoveis_xgb, as.matrix(X_test_treat))
# Plot predictions (on x axis) vs actual bike rental count
ggplot(y_test, aes(x = pred, y = price)) +
geom_point() +
geom_abline()
# Make predictions
y_test$pred <- predict(imoveis_xgb, as.matrix(X_test_treat))
View(y_test)
y_test <- test_fact$price
# Make predictions
comparacao <- data_frame(pred = predict(imoveis_xgb, as.matrix(X_test_treat)), price = y_test)
ggplot(comparacao, aes(x = pred, y = price)) +
geom_point() +
geom_abline()
defaultSummary(data.frame(obs = y_test, pred= predict(imoveis_xgb, as.matrix(X_test_treat))))
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2))
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2)))
comparacao
comparacao %>%
mutate(residuals = price - pred)
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2)))
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars, scale=TRUE)
View(X_train_treat)
comparacao %>%
gather(tipo, valor, price, pred) %>%
ggplot(aes(valor, fill = tipo)) +
geom_density()
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars)
View(X_train_treat)
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 500, # n de rounds total
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.1, # taxa de aprendizagem
max_depth = 6, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
xgb_cv
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 1000, # n de rounds total
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.1, # taxa de aprendizagem
max_depth = 10, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
xgb_cv
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean)) # find the index of min(test_rmse_mean)
imoveis_xgb <- xgboost(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 57,
objective = 'reg:linear',
eta = 0.1,
depth = 10,
verbose = 0
)
# Make predictions
comparacao <- data_frame(pred = predict(imoveis_xgb, as.matrix(X_test_treat)), price = y_test)
comparacao %>%
gather(tipo, valor, price, pred) %>%
ggplot(aes(valor, fill = tipo)) +
geom_density()
comparacao %>%
gather(tipo, valor, price, pred) %>%
ggplot(aes(valor, fill = tipo)) +
geom_density(alpha = .5)
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2)))
# Make predictions
comparacao <- data_frame(pred = predict(imoveis_xgb, as.matrix(X_test_treat)), price = y_test)
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2)))
prepare
?prepare
treatplan <- designTreatmentsZ(X_train, vars_input, scale = T)
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars, scale = T)
summary(X_train_treat)
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars)
summary(X_train_treat)
