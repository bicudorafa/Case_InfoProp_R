install.packages('vtreat')
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
imoveis_clean <- imoveis_clean %>% filter(!(price == 18000))
var_t <- list(imoveis_clean_rua %>% arrange(desc(total_a)),
imoveis_clean_condominio %>% arrange(desc(total_a)),
imoveis_clean_agent %>% arrange(desc(total_a)))
plots_total <- list()
for (i in 1:length(var_t)){
plots_total[[i]] <- ggplot(var_t[[i]], aes(x = factor(var_t[[i]][[1]], levels = var_t[[i]][[1]]),
y = total_a)) +
geom_bar(stat="identity", width=.5) +
coord_flip() +
labs(title=paste('Anúncios x ', names(var_t[[i]])[[1]]),
x = names(names(var_t[[i]])[[1]]),
y = 'Anúncios')
print(plots_total[[i]])
}
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage)
View(imoveis_clean)
# agregação dos valores para não causar overfitting pela baixa quantidade de valores
roomsBathGarage <- imoveis_clean %>%
select(c(rooms, bathrooms, garage, property_d)) %>%
mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
garage_coerc = ifelse(garage > 5, 5, garage))
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d'))
options (error = browser)
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
a
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo)
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente)
View(imoveis_final)
roomsBathGarage <- imoveis_clean %>%
select(c(rooms, bathrooms, garage, property_d)) %>%
mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
garage_coerc = ifelse(garage > 5, 5, garage)) %>%
select(-c(rooms, bathrooms, garage, property_d))
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d'))
View(roomsBathGarage)
roomsBathGarage <- imoveis_clean %>%
select(c(rooms, bathrooms, garage, property_d)) %>%
mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
garage_coerc = ifelse(garage > 5, 5, garage)) %>%
select(-c(rooms, bathrooms, garage))
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage, by = c('property_d')) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
View(imoveis_final)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
#Carregando pacote necessario e iniciando seed do projeto
library(caret)
library(vtreat)
library(xgboost)
set.seed(666)
sample <- createDataPartition(imoveis_final$price, times = 1, list = F, p = .7)
train_sample <- imoveis_final[sample, ]
test_sample <- imoveis_final[-sample, ]
View(imoveis_final)
## Pre processamento usando vtreat
X_train <- train_sample[-1]
View(X_train)
y_trains <- train_sample[1]
vars_input <- names(X_train)
treatplan <- designTreatmentsZ(X_train, vars)
vars_input <- names(X_train)
treatplan <- designTreatmentsZ(X_train, vars_input)
summary(imoveis_final)
View(imoveis)
library(dplyr)
library(stringr)
library(lubridate)
library(ggplot2)
theme_set(theme_bw())
library(tidyr)
library(caret)
library(vtreat)
library(xgboost)
set.seed(666)
# funcao para transformar variaveis em fact
toFactor <- function(df, features) {
for (feature in features) {
df[[feature]] <- factor(df[[feature]], exclude = NULL)
# exclude é importantíssimo pra considerar NA como classe
}
return(df)
}
# dfs em factor
train_fact <- toFactor(train_sample, c('rooms_coerc', 'bathrooms_coerc','garage_coerc'))
test_fact <- toFactor(test_sample, c('rooms_coerc', 'bathrooms_coerc','garage_coerc'))
X_train <- train_fact[-1]
y_trains <- train_fact[1]
vars_input <- names(X_train)
treatplan <- designTreatmentsZ(X_train, vars_input)
treatplan %>%
use_series(scoreFrame)
treatplan %>%
magrittr::use_series(scoreFrame)
scoreFrame <- treatplan %>%
magrittr::use_series(scoreFrame) %>% # forma dplyr de fazer subsetting "$"
select(varName, origName, code)
scoreFrame %>%
filter(code %in% c('clean', 'lev')) %>%
magrittr::use_series(varName)
y_train <- train_fact[1]
# obtenção do string vector somente com as variáveis requeridas
novas_vars <- scoreFrame %>%
filter(code %in% c('clean', 'lev')) %>%
magrittr::use_series(varName)
novas_vars
X_test <- test_fact[-1]
y_test <- test_fact[1]
# dfs tratados
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars)
X_test_treat <- prepare(treatplan, X_test, varRestriction = novas_vars)
View(X_train_treat)
typeof(X_test_treat)
# Modelo usando xgboost
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 100, # n de rounds
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.3, # taxa de aprendizagem
max_depth = 6, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
# Modelo usando xgboost
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 100, # n de rounds
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.3, # taxa de aprendizagem
max_depth = 6, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
options (error = browser)
y_train <- train_fact$price
# Modelo usando xgboost
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 100, # n de rounds
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.3, # taxa de aprendizagem
max_depth = 6, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
y_test <- test_fact$price
# Determine and print how many trees minimize training and test error
elog %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))   # find the index of min(test_rmse_mean)
# Determine and print how many trees minimize training and test error
xgb_cv$evaluation_log %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))   # find the index of min(test_rmse_mean)
xgb_cv
View(X_train)
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))   # find the index of min(test_rmse_mean)
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
select(ntrees.test)
nrounds_ideal <- xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
select(ntrees.test)
View(nrounds_ideal)
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
as.numeric()
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
select(ntrees.test) %>% as.numeric()
nrounds_ideal <- xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))  %>%  # find the index of min(test_rmse_mean)
select(ntrees.test) %>% as.numeric()
nrounds_ideal <- xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean))
nrounds_ideal
# Modelo
imoveis_xgb <- xgboost(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 30,
objective = 'reg:linear',
eta = 0.3,
depth = 6,
verbose = 0
)
View(imoveis_xgb)
summary(imoveis_xgb)
# Make predictions
X_test_treat$pred <- predict(imoveis_xgb, as.matrix(X_test_treat))
ggplot(X_test_treat, aes(x = pred, y = price)) +
geom_point() +
geom_abline()
X_test_treat <- prepare(treatplan, X_test, varRestriction = novas_vars)
# Make predictions
y_test$pred <- predict(imoveis_xgb, as.matrix(X_test_treat))
# Plot predictions (on x axis) vs actual bike rental count
ggplot(y_test, aes(x = pred, y = price)) +
geom_point() +
geom_abline()
# Make predictions
y_test$pred <- predict(imoveis_xgb, as.matrix(X_test_treat))
View(y_test)
y_test <- test_fact$price
# Make predictions
comparacao <- data_frame(pred = predict(imoveis_xgb, as.matrix(X_test_treat)), price = y_test)
ggplot(comparacao, aes(x = pred, y = price)) +
geom_point() +
geom_abline()
defaultSummary(data.frame(obs = y_test, pred= predict(imoveis_xgb, as.matrix(X_test_treat))))
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2))
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2)))
comparacao
comparacao %>%
mutate(residuals = price - pred)
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2)))
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars, scale=TRUE)
View(X_train_treat)
comparacao %>%
gather(tipo, valor, price, pred) %>%
ggplot(aes(valor, fill = tipo)) +
geom_density()
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars)
View(X_train_treat)
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 500, # n de rounds total
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.1, # taxa de aprendizagem
max_depth = 6, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
xgb_cv
xgb_cv <- xgb.cv(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 1000, # n de rounds total
nfold = 5, # número de cvs
objective = "reg:linear", # continuos outcome
eta = 0.1, # taxa de aprendizagem
max_depth = 10, # maior profundidade das árvores
early_stopping_rounds = 10, # para após x rounds sem melhora
verbose = 0    # silêncio
)
xgb_cv
xgb_cv %>%
magrittr::use_series(evaluation_log) %>%
summarize(ntrees.train = which.min(train_rmse_mean),   # find the index of min(train_rmse_mean)
ntrees.test  = which.min(test_rmse_mean)) # find the index of min(test_rmse_mean)
imoveis_xgb <- xgboost(data = as.matrix(X_train_treat),
label = y_train,
nrounds = 57,
objective = 'reg:linear',
eta = 0.1,
depth = 10,
verbose = 0
)
# Make predictions
comparacao <- data_frame(pred = predict(imoveis_xgb, as.matrix(X_test_treat)), price = y_test)
comparacao %>%
gather(tipo, valor, price, pred) %>%
ggplot(aes(valor, fill = tipo)) +
geom_density()
comparacao %>%
gather(tipo, valor, price, pred) %>%
ggplot(aes(valor, fill = tipo)) +
geom_density(alpha = .5)
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2)))
# Make predictions
comparacao <- data_frame(pred = predict(imoveis_xgb, as.matrix(X_test_treat)), price = y_test)
comparacao %>%
mutate(residuals = price - pred) %>%
summarize(rmse = sqrt(mean(residuals**2)))
prepare
?prepare
treatplan <- designTreatmentsZ(X_train, vars_input, scale = T)
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars, scale = T)
summary(X_train_treat)
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
X_train_treat <- prepare(treatplan, X_train, varRestriction = novas_vars)
summary(X_train_treat)
summary(imoveis_final)
View(imoveis_final)
View(X_train_treat)
summary(X_train_treat)
library(dplyr)
library(tidyr)
library(caret)
library(vtreat)
library(xgboost)
set.seed(666)
View(train_fact)
## Pre processamento usando vtreat
treatplan <- designTreatmentsN(train_fact, vars_input, 'price')
treatplan %>%
magrittr::use_series(scoreFrame)
## Pre processamento usando vtreat
treatplan <- designTreatmentsN(train_fact, names(train_fact), 'price')
View(train_fact)
# df Scoreframe para conseguir nomes das novas variáveis
scoreFrame <- treatplan %>%
magrittr::use_series(scoreFrame) %>% # forma dplyr de fazer subsetting "$"
select(varName, origName, code)
novas_vars <- scoreFrame %>%
filter(code %in% c('clean', 'lev')) %>%
magrittr::use_series(varName)
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
train_treat <- prepare(treatplan, train_fact, varRestriction = novas_vars, scale = T)
View(train_treat)
summary(train_treat)
ggplot(train_fact, aes(area)) +
geom_density()
ggplot(train_treat, aes(area_clean)) +
geom_density()
var(train_fact$area)
summary(train_fact$area)
var(train_fact$area, na.rm = T)
var(train_clean$area_clean, na.rm = T)
var(train_treat$area_clean, na.rm = T)
var(X_train_treat$area_clean)
prepare()
prepare
# dfs tratados (opção de colocar argumento scale pra testar com modelos sensitivos como knn, lineares em geral)
train_treat <- prepare(treatplan, train_fact, varRestriction = novas_vars, center = T, scale = T)
View(train_sample)
# Funcao para automatizar normalizacao
scale.features <- function(df, variables){
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center=T, scale=T)
}
return(df)
}
# Transformação do df para modelagem
fact_vars <-  c('rooms_coerc', 'bathrooms_coerc','garage_coerc')
setdiff(names(imoveis_final), fact_vars)
# funcao para transformar variaveis em fact e escalar
toFactor <- function(df, features) {
for (feature in features) {
df[[feature]] <- factor(df[[feature]], exclude = NULL)
# exclude é importantíssimo pra considerar NA como classe
}
return(df)
}
# Funcao para automatizar normalizacao
scale.features <- function(df, variables){
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center=T, scale=T)
}
return(df)
}
# Transformação do df para modelagem
fact_vars <-  c('rooms_coerc', 'bathrooms_coerc','garage_coerc')
imoveis_fact <- toFactor(imoveis_final,fact_vars)
imoveis_scale <- scale.features(imoveis_fact, setdiff(names(imoveis_final), fact_vars))
sample <- createDataPartition(imoveis_scale$price, list = F, p = .7)
train_sample <- imoveis_final[sample, ]
test_sample <- imoveis_final[-sample, ]
View(train_sample)
View(X_test_treat)
# uso do pacte vtreat para one hot encoding
treatPlan <- designTreatmentsN(imoveis_final, names(imoveis_final), 'price')
treatplan %>%
magrittr::use_series(scoreFrame)
treatPlan %>%
magrittr::use_series(scoreFrame)
install.packages('mlr')
library(mlr)
imoveis_fact <- imoveis_final %>%
mutate_at(
.vars = vars('rooms_coerc', 'bathrooms_coerc','garage_coerc'"),
.funs = funs(as.factor(.))
)
imoveis_fact <- imoveis_final %>%
mutate_at(
.vars = vars('rooms_coerc', 'bathrooms_coerc','garage_coerc'"),
.funs = funs(as.factor(.))
)
imoveis_fact <- imoveis_final %>%
mutate_at(
.vars = vars('rooms_coerc', 'bathrooms_coerc','garage_coerc'),
.funs = funs(as.factor(.))
)
View(imoveis_fact)
glimpse(imoveis_fact)
# Imputador dos valores missing
imp <- impute(
imoveis_fact,
classes = list(
factor = imputeMode(),
integer = imputeMean(),
numeric = imputeMean()
)
)
imoveis_imp <- imp$data
# Sumarizando as colunas
summarizeColumns(imoveis_imp) %>%
kable(digits = 2)
# Sumarizando as colunas
summarizeColumns(imoveis_imp)
# Sumarizando as colunas
summarizeColumns(imoveis_imp) %>%
knitr::kable(digits = 2)
# Normalização
imoveis_norm <- normalizeFeatures(imoveis_imp, target = "price")
View(imoveis_norm)
# One hot encoding
imoveis_preProc <- createDummyFeatures(
imoveis_norm, target = "price",
cols = c(
"rooms_coerc",
"bathrooms_coerc",
"garage_coerc"
)
)
View(imoveis_preProc)
