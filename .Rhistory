comparacao %>%
tidyr::gather(tipo, valor, price, pred_lm, pred_xgb) %>%
filter(!(tipo == 'pred_lm')) %>%
ggplot(aes(valor, fill = tipo)) +
geom_density(alpha = .5)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
## Investigacao outliers
imoveis_clean %>% filter(log(area) > 10 | log(price) < 10 | log(condominium_fee) > 10)
imoveis_clean %>% filter(bathrooms == 54)
# outliers de area e price: informações muito discrepantes em relação à realidade. Provavelmente, erros de digitação
imoveis_clean$area[which(imoveis$area == 30700)] <- NA
imoveis_clean <- imoveis_clean %>% filter(!(price == 18000))
imoveis_clean$condominium_fee[which(imoveis$condominium_fee == 460000)] <- NA
# o apartamento com mais de 54 banheiros parece muito fora da media em relacao ao seu preco e area
imoveis_clean$bathrooms[which(imoveis$bathrooms == 54)] <- NA
## Investigacao outliers
imoveis_clean %>% filter(log(area) > 10 | log(price) < 10 | log(condominium_fee) > 10) %>%
knitr::kable()
imoveis_clean %>% filter(bathrooms == 54)
# outliers de area e price: informações muito discrepantes em relação à realidade. Provavelmente, erros de digitação
imoveis_clean$area[which(imoveis$area == 30700)] <- NA
imoveis_clean <- imoveis_clean %>% filter(!(price == 18000))
imoveis_clean$condominium_fee[which(imoveis$condominium_fee == 460000)] <- NA
# o apartamento com mais de 54 banheiros parece muito fora da media em relacao ao seu preco e area
imoveis_clean$bathrooms[which(imoveis$bathrooms == 54)] <- NA
tuned_params <- tuneParams(
learner = xgb_model,
task = task_train,
resampling = resample_desc,
measures = rmse,       # R-Squared performance measure, this can be changed to one or many
par.set = xgb_params,
control = control
)
source('~/GitHub/Case_InfoProp_R/Case_InfoProp.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/Case_InfoProp_R/ML_mlr.R', encoding = 'UTF-8', echo=TRUE)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# Carrehando pacote necessario
library(dplyr)
# Pacotes necessários
library(stringr)
library(lubridate)
### Data celaning
imoveis_clean = imoveis
# Carrehando pacote necessario
library(dplyr)
# Obtencao dos dados
imoveis <- as.tbl(read.csv2('Crawler_vivareal_venda_2017_desafio.csv', stringsAsFactors = F, encoding = "UTF-8",
na.strings = ""))
glimpse(imoveis)
### Data celaning
imoveis_clean = imoveis
# Pacotes necessários
library(stringr)
library(lubridate)
# data
names(imoveis_clean) <- str_replace(names(imoveis_clean), 'X.U.FEFF.date', 'Data')
imoveis_clean$Data <- as.Date(imoveis$X.U.FEFF.date, format = '%d/%m/%Y')
year(imoveis_clean$Data) <- year(imoveis_clean$Data)+2000
# lat e long
imoveis_clean$longitude <- gsub(".", "", imoveis$longitude, fixed = TRUE) %>%
sub("(\\d{2})", "\\1\\.", .) %>%
as.numeric()
imoveis_clean$latitude <- gsub(".", "", imoveis$latitude, fixed = TRUE) %>%
sub("(\\d{2})", "\\1\\.", .) %>%
as.numeric()
# price_by_sqm
imoveis_clean$price_by_sqm <- as.numeric(imoveis_clean$price_by_sqm)
# condominium_fee e iptu
imoveis_clean$condominium_fee <- str_replace_all(imoveis$condominium_fee, 'R\\$', '') %>%
str_replace_all('[:punct:]', '') %>%
as.numeric()
imoveis_clean$iptu <- str_replace_all(imoveis$iptu, 'R\\$', '') %>%
str_replace_all('[:punct:]', '') %>%
as.numeric()
# visualizacao do novo df
glimpse(imoveis_clean)
summary(imoveis_clean)
## Visualizacao interativa
library(leaflet)
leaflet(data = imoveis_clean) %>% addTiles() %>%
addMarkers(~longitude, ~latitude, popup = ~as.character(property_d),
clusterOptions = markerClusterOptions()
)
# visualizacao das variaveis continuas
library(ggplot2)
cont_vars <- c('area', 'iptu','condominium_fee')
plots_cont <- list()
for (var in cont_vars) {
plots_cont[[var]] <- ggplot(imoveis_clean, aes_string(log(imoveis_clean[[var]]), log(imoveis_clean[['price']]))) +
geom_point() +
geom_smooth(method = lm, se = F) +
ggtitle(paste(var, 'x price')) +
theme_minimal()
print(plots_cont[[var]])
}
# visualizacao das variaveis factor
fact_vars <- c('bairro', 'rooms', 'bathrooms','garage')
plots_fact <- list()
for (var in fact_vars) {
plots_fact[[var]] <- ggplot(imoveis_clean, aes_string(x = as.factor(imoveis_clean[[var]]), log(imoveis_clean[['price']]))) +
geom_boxplot() +
ggtitle(paste(var, 'x price')) +
theme_minimal()
print(plots_fact[[var]])
}
plots_fact_c <- list()
for (var in fact_vars) {
plots_fact_c[[var]] <- ggplot(imoveis_clean, aes_string(x = as.factor(imoveis_clean[[var]]))) +
geom_bar(stat = 'count') +
ggtitle(paste('Total Observations in ',var)) +
theme_minimal()
print(plots_fact_c[[var]])
}
## Investigacao outliers
imoveis_clean %>% filter(log(area) > 10 | log(price) < 10 | log(condominium_fee) > 10)
imoveis_clean %>% filter(bathrooms == 54)
# outliers de area e price: informações muito discrepantes em relação à realidade. Provavelmente, erros de digitação
imoveis_clean$area[which(imoveis$area == 30700)] <- NA
imoveis_clean <- imoveis_clean %>% filter(!(price == 18000))
imoveis_clean$condominium_fee[which(imoveis$condominium_fee == 460000)] <- NA
# o apartamento com mais de 54 banheiros parece muito fora da media em relacao ao seu preco e area
imoveis_clean$bathrooms[which(imoveis$bathrooms == 54)] <- NA
# agregação dos valores para não causar overfitting pela baixa quantidade de valores
roomsBathGarage <- imoveis_clean %>%
select(c(rooms, bathrooms, garage)) %>%
mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
garage_coerc = ifelse(garage > 5, 5, garage))
# criacao dos dfs comas supostas novas variaveis de interesse
imoveis_clean_rua <- imoveis_clean %>%
group_by(rua) %>%
summarise(total_a = n(),
media_p = mean(price_by_sqm, na.rm = T)) %>%
filter(!(is.na(rua)))
imoveis_clean_condominio <- imoveis_clean %>%
group_by(condominio) %>%
summarise(total_a = n(),
media_p = mean(price_by_sqm, na.rm = T)) %>%
filter(!(is.na(condominio)))
# como ha agencias sem nenhuma entrada, filtro antes de achar as variaves finais
imoveis_clean_agent <- imoveis_clean %>%
group_by(agent) %>%
summarise(total_a = n(),
media_p = mean(price_by_sqm, na.rm = T)) %>%
filter(!(is.na(agent))) %>%
filter(!(is.na(media_p)))
# plot total_a
var_t <- list(imoveis_clean_rua %>% arrange(desc(total_a)),
imoveis_clean_condominio %>% arrange(desc(total_a)),
imoveis_clean_agent %>% arrange(desc(total_a)))
plots_total <- list()
for (i in 1:length(var_t)){
plots_total[[i]] <- ggplot(var_t[[i]], aes(x = factor(var_t[[i]][[1]], levels = var_t[[i]][[1]]),
y = total_a)) +
geom_bar(stat="identity", width=.5) +
coord_flip() +
labs(title=paste('Anúncios x ', names(var_t[[i]])[[1]]),
x = names(names(var_t[[i]])[[1]]),
y = 'Anúncios')
print(plots_total[[i]])
}
# plot da media_p
var_m <- list(imoveis_clean_rua %>% arrange(desc(media_p)),
imoveis_clean_condominio %>% arrange(desc(media_p)),
imoveis_clean_agent %>% arrange(desc(media_p)))
plots_media <- list()
for (i in 1:length(var_m)){
plots_media[[i]] <- ggplot(var_m[[i]], aes(x = factor(var_m[[i]][[1]], levels = var_m[[i]][[1]]),
y = media_p)) +
geom_bar(stat="identity", width=.5) +
coord_flip() +
labs(title=paste('Media x ', names(var_m[[i]])[[1]]),
x = names(names(var_m[[i]])[[1]]),
y = 'Media')
print(plots_media[[i]])
}
# variaveis criadas
vars_rua <- imoveis_clean_rua %>% select(rua, anuncio_rua = total_a, valores_rua = media_p)
vars_condo <- imoveis_clean_condominio %>% select(condominio, anuncio_condo = total_a, valores_condo = media_p)
vars_agente <- imoveis_clean_agent %>% select(agent, anuncio_agente = total_a, valores_agente = media_p)
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
glimpse(imoveis_final)
# Função mais eficiente para featurização
imoveis_fact <- imoveis_final %>%
mutate_at(
.vars = vars('rooms_coerc', 'bathrooms_coerc','garage_coerc'),
.funs = funs(as.factor(.))
)
glimpse(imoveis_fact)
## Pacote MLR
# Pacote
library(mlr)
set.seed(666)
# Imputador dos valores missing
imp <- impute(
imoveis_fact,
classes = list(
factor = imputeMode(),
integer = imputeMean(),
numeric = imputeMean()
)
)
imoveis_imp <- imp$data
# Sumarizando as colunas
summarizeColumns(imoveis_imp) %>%
knitr::kable(digits = 2) # gerador de tabelas muito prático do knitr
# Normalização
imoveis_norm <- normalizeFeatures(imoveis_imp, target = "price")
# One hot encoding
imoveis_preProc <- createDummyFeatures(
imoveis_norm, target = "price",
cols = c(
"rooms_coerc",
"bathrooms_coerc",
"garage_coerc"
)
)
# Criação do Task para Regressão (objeto usado nas operações do pacote)
task <- makeRegrTask(id = 'Imoveis_SP', data = imoveis_preProc, target = 'price')
# train test split (holdout é o método de resample de separar em train/test)
holdout <- makeResampleInstance('Holdout', task)
task_train <- subsetTask(task, holdout$train.inds[[1]])
task_test <- subsetTask(task, holdout$test.inds[[1]])
## Modelo linear básico
# modelo padrão linear
regr.lm <- makeLearner(id = 'lm', 'regr.lm')
# treinamento modelo
lm <- train(regr.lm, task_train)
## XGBoost
# Criação do modelo simples
xgb_model <- makeLearner("regr.xgboost")
# Grid de alguns parâmetros
xgb_params <- makeParamSet(
# The number of trees in the model (each one built sequentially)
makeIntegerParam("nrounds", lower = 100, upper = 2000),
# number of splits in each tree
makeIntegerParam("max_depth", lower = 1, upper = 10),
# "shrinkage" - prevents overfitting
makeNumericParam("eta", lower = .1, upper = .5),
# L2 regularization - prevents overfitting
makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x)
)
# Controle da tunagem randômica
control <- makeTuneControlRandom(maxit = 3) # maxit represente tempo máximo de 1 min para iterações
# Plano de resampling
resample_desc <- makeResampleDesc("CV", iters = 5)
# tunador dos hiper parâmetros
tuned_params <- tuneParams(
learner = xgb_model,
task = task_train,
resampling = resample_desc,
measures = rmse,       # R-Squared performance measure, this can be changed to one or many
par.set = xgb_params,
control = control
)
## Modelo linear básico
# modelo padrão linear
regr.lm <- makeLearner(id = 'lm', 'regr.lm')
# treinamento modelo
lm <- train(regr.lm, task_train)
## XGBoost
# Criação do modelo simples
xgb_model <- makeLearner("regr.xgboost")
# Grid de alguns parâmetros
xgb_params <- makeParamSet(
# The number of trees in the model (each one built sequentially)
makeIntegerParam("nrounds", lower = 100, upper = 2000),
# number of splits in each tree
makeIntegerParam("max_depth", lower = 1, upper = 10),
# "shrinkage" - prevents overfitting
makeNumericParam("eta", lower = .1, upper = .5),
# L2 regularization - prevents overfitting
makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x)
)
# Controle da tunagem randômica
control <- makeTuneControlRandom(maxit = 1) # maxit represente tempo máximo de 1 min para iterações
# Plano de resampling
resample_desc <- makeResampleDesc("CV", iters = 5)
# tunador dos hiper parâmetros
tuned_params <- tuneParams(
learner = xgb_model,
task = task_train,
resampling = resample_desc,
measures = rmse,       # R-Squared performance measure, this can be changed to one or many
par.set = xgb_params,
control = control
)
## Modelo linear básico
# modelo padrão linear
regr.lm <- makeLearner(id = 'lm', 'regr.lm')
# treinamento modelo
lm <- train(regr.lm, task_train)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# Carrehando pacote necessario
library(dplyr)
# Obtencao dos dados
imoveis <- as.tbl(read.csv2('Crawler_vivareal_venda_2017_desafio.csv', stringsAsFactors = F, encoding = "UTF-8",
na.strings = ""))
glimpse(imoveis)
### Data celaning
imoveis_clean = imoveis
# Pacotes necessários
library(stringr)
library(lubridate)
# data
names(imoveis_clean) <- str_replace(names(imoveis_clean), 'X.U.FEFF.date', 'Data')
imoveis_clean$Data <- as.Date(imoveis$X.U.FEFF.date, format = '%d/%m/%Y')
year(imoveis_clean$Data) <- year(imoveis_clean$Data)+2000
# lat e long
imoveis_clean$longitude <- gsub(".", "", imoveis$longitude, fixed = TRUE) %>%
sub("(\\d{2})", "\\1\\.", .) %>%
as.numeric()
imoveis_clean$latitude <- gsub(".", "", imoveis$latitude, fixed = TRUE) %>%
sub("(\\d{2})", "\\1\\.", .) %>%
as.numeric()
# price_by_sqm
imoveis_clean$price_by_sqm <- as.numeric(imoveis_clean$price_by_sqm)
# condominium_fee e iptu
imoveis_clean$condominium_fee <- str_replace_all(imoveis$condominium_fee, 'R\\$', '') %>%
str_replace_all('[:punct:]', '') %>%
as.numeric()
imoveis_clean$iptu <- str_replace_all(imoveis$iptu, 'R\\$', '') %>%
str_replace_all('[:punct:]', '') %>%
as.numeric()
# visualizacao do novo df
glimpse(imoveis_clean)
summary(imoveis_clean)
# visualizacao das variaveis continuas
library(ggplot2)
cont_vars <- c('area', 'iptu','condominium_fee')
plots_cont <- list()
for (var in cont_vars) {
plots_cont[[var]] <- ggplot(imoveis_clean, aes_string(log(imoveis_clean[[var]]), log(imoveis_clean[['price']]))) +
geom_point() +
geom_smooth(method = lm, se = F) +
ggtitle(paste(var, 'x price')) +
theme_minimal()
print(plots_cont[[var]])
}
# visualizacao das variaveis factor
fact_vars <- c('bairro', 'rooms', 'bathrooms','garage')
plots_fact <- list()
for (var in fact_vars) {
plots_fact[[var]] <- ggplot(imoveis_clean, aes_string(x = as.factor(imoveis_clean[[var]]), log(imoveis_clean[['price']]))) +
geom_boxplot() +
ggtitle(paste(var, 'x price')) +
theme_minimal()
print(plots_fact[[var]])
}
plots_fact_c <- list()
for (var in fact_vars) {
plots_fact_c[[var]] <- ggplot(imoveis_clean, aes_string(x = as.factor(imoveis_clean[[var]]))) +
geom_bar(stat = 'count') +
ggtitle(paste('Total Observations in ',var)) +
theme_minimal()
print(plots_fact_c[[var]])
}
## Investigacao outliers
imoveis_clean %>% filter(log(area) > 10 | log(price) < 10 | log(condominium_fee) > 10)
imoveis_clean %>% filter(bathrooms == 54)
# outliers de area e price: informações muito discrepantes em relação à realidade. Provavelmente, erros de digitação
imoveis_clean$area[which(imoveis$area == 30700)] <- NA
imoveis_clean <- imoveis_clean %>% filter(!(price == 18000))
imoveis_clean$condominium_fee[which(imoveis$condominium_fee == 460000)] <- NA
# o apartamento com mais de 54 banheiros parece muito fora da media em relacao ao seu preco e area
imoveis_clean$bathrooms[which(imoveis$bathrooms == 54)] <- NA
# agregação dos valores para não causar overfitting pela baixa quantidade de valores
roomsBathGarage <- imoveis_clean %>%
select(c(rooms, bathrooms, garage)) %>%
mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
garage_coerc = ifelse(garage > 5, 5, garage))
# criacao dos dfs comas supostas novas variaveis de interesse
imoveis_clean_rua <- imoveis_clean %>%
group_by(rua) %>%
summarise(total_a = n(),
media_p = mean(price_by_sqm, na.rm = T)) %>%
filter(!(is.na(rua)))
imoveis_clean_condominio <- imoveis_clean %>%
group_by(condominio) %>%
summarise(total_a = n(),
media_p = mean(price_by_sqm, na.rm = T)) %>%
filter(!(is.na(condominio)))
# como ha agencias sem nenhuma entrada, filtro antes de achar as variaves finais
imoveis_clean_agent <- imoveis_clean %>%
group_by(agent) %>%
summarise(total_a = n(),
media_p = mean(price_by_sqm, na.rm = T)) %>%
filter(!(is.na(agent))) %>%
filter(!(is.na(media_p)))
# plot total_a
var_t <- list(imoveis_clean_rua %>% arrange(desc(total_a)),
imoveis_clean_condominio %>% arrange(desc(total_a)),
imoveis_clean_agent %>% arrange(desc(total_a)))
plots_total <- list()
for (i in 1:length(var_t)){
plots_total[[i]] <- ggplot(var_t[[i]], aes(x = factor(var_t[[i]][[1]], levels = var_t[[i]][[1]]),
y = total_a)) +
geom_bar(stat="identity", width=.5) +
coord_flip() +
labs(title=paste('Anúncios x ', names(var_t[[i]])[[1]]),
x = names(names(var_t[[i]])[[1]]),
y = 'Anúncios')
print(plots_total[[i]])
}
# plot da media_p
var_m <- list(imoveis_clean_rua %>% arrange(desc(media_p)),
imoveis_clean_condominio %>% arrange(desc(media_p)),
imoveis_clean_agent %>% arrange(desc(media_p)))
plots_media <- list()
for (i in 1:length(var_m)){
plots_media[[i]] <- ggplot(var_m[[i]], aes(x = factor(var_m[[i]][[1]], levels = var_m[[i]][[1]]),
y = media_p)) +
geom_bar(stat="identity", width=.5) +
coord_flip() +
labs(title=paste('Media x ', names(var_m[[i]])[[1]]),
x = names(names(var_m[[i]])[[1]]),
y = 'Media')
print(plots_media[[i]])
}
# variaveis criadas
vars_rua <- imoveis_clean_rua %>% select(rua, anuncio_rua = total_a, valores_rua = media_p)
vars_condo <- imoveis_clean_condominio %>% select(condominio, anuncio_condo = total_a, valores_condo = media_p)
vars_agente <- imoveis_clean_agent %>% select(agent, anuncio_agente = total_a, valores_agente = media_p)
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
left_join(roomsBathGarage) %>%
left_join(vars_rua) %>%
left_join(vars_condo) %>%
left_join(vars_agente) %>%
select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number,
latitude, longitude, property_d, url))
glimpse(imoveis_final)
# Função mais eficiente para featurização
imoveis_fact <- imoveis_final %>%
mutate_at(
.vars = vars('rooms_coerc', 'bathrooms_coerc','garage_coerc'),
.funs = funs(as.factor(.))
)
glimpse(imoveis_fact)
## Pacote MLR
# Pacote
library(mlr)
set.seed(666)
# Imputador dos valores missing
imp <- impute(
imoveis_fact,
classes = list(
factor = imputeMode(),
integer = imputeMean(),
numeric = imputeMean()
)
)
imoveis_imp <- imp$data
# Sumarizando as colunas
summarizeColumns(imoveis_imp) %>%
knitr::kable(digits = 2) # gerador de tabelas muito prático do knitr
# Normalização
imoveis_norm <- normalizeFeatures(imoveis_imp, target = "price")
# One hot encoding
imoveis_preProc <- createDummyFeatures(
imoveis_norm, target = "price",
cols = c(
"rooms_coerc",
"bathrooms_coerc",
"garage_coerc"
)
)
# Criação do Task para Regressão (objeto usado nas operações do pacote)
task <- makeRegrTask(id = 'Imoveis_SP', data = imoveis_preProc, target = 'price')
# train test split (holdout é o método de resample de separar em train/test)
holdout <- makeResampleInstance('Holdout', task)
task_train <- subsetTask(task, holdout$train.inds[[1]])
task_test <- subsetTask(task, holdout$test.inds[[1]])
# modelo padrão linear
regr.lm <- makeLearner(id = 'lm', 'regr.lm')
# treinamento modelo
lm <- train(regr.lm, task_train)
## XGBoost
# Criação do modelo simples
xgb_model <- makeLearner("regr.xgboost")
# Grid de alguns parâmetros
xgb_params <- makeParamSet(
# The number of trees in the model (each one built sequentially)
makeIntegerParam("nrounds", lower = 100, upper = 2000),
# number of splits in each tree
makeIntegerParam("max_depth", lower = 1, upper = 10),
# "shrinkage" - prevents overfitting
makeNumericParam("eta", lower = .1, upper = .5),
# L2 regularization - prevents overfitting
makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x)
)
# Controle da tunagem randômica
control <- makeTuneControlRandom(maxit = 1) # maxit represente tempo máximo de 1 min para iterações
# Plano de resampling
resample_desc <- makeResampleDesc("CV", iters = 5)
# tunador dos hiper parâmetros
tuned_params <- tuneParams(
learner = xgb_model,
task = task_train,
resampling = resample_desc,
measures = rmse,       # R-Squared performance measure, this can be changed to one or many
par.set = xgb_params,
control = control
)
