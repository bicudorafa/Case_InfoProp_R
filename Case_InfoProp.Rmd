---
title: "Case_InfroProp"
author: "Rafael Bicudo Rosa"
date: "28 de agosto de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Business Case - InfoProp

O objetivo deste trabalho é realizar uma análise minuciosa de dados imobiliários da cidade de São Paulo no ano de 2017. Através da limpeza e a vizualização dos relacionamentos entre as variáveis disponíves, a ideia é tentar captar insights importantes e, em seguida, construir um modelo de precificação baseado nas informações encontradas.

## Etapa 1 - Coleta dos Dados

Para iniciar a análise, começarei pela abertura do arquivo através da função base do sistema e, em seguida, com o auxílio do pacote dplyr, tranformá-la-ei em um tbl.df para obter as melhores possibilidades de manipulação de dados.


```{r coleta}
# Carrehando pacote necessario
library(dplyr)

# Obtencao dos dados
imoveis <- as.tbl(read.csv2('Crawler_vivareal_venda_2017_desafio.csv', stringsAsFactors = F, encoding = "UTF-8",
                            na.strings = ""))
glimpse(imoveis)

```


## Etapa 2 - Limpeza e Preparação dos dados

O primeiro passo será a limpeza dos dados. Após realizar a abertura do arquivo, identifiquei as necessidades de correção nas variáveis, das quais se destacam: problema nos encodings das variáveis data, latitude e longitude; e o formato de texto das variáveis numéricas. Os pacotes selecionados para tais tarefas foram o lubridate e stringr. Ao término do processo, percebe-se a diferença no novo dataframe.

```{r normalizando}
### Data celaning
imoveis_clean = imoveis

# Pacotes necessários
library(stringr)
library(lubridate)

# data
names(imoveis_clean) <- str_replace(names(imoveis_clean), 'X.U.FEFF.date', 'Data')
imoveis_clean$Data <- as.Date(imoveis$X.U.FEFF.date, format = '%d/%m/%Y')
year(imoveis_clean$Data) <- year(imoveis_clean$Data)+2000

# lat e long
imoveis_clean$longitude <- gsub(".", "", imoveis$longitude, fixed = TRUE) %>%
  sub("(\\d{2})", "\\1\\.", .) %>% 
  as.numeric()
imoveis_clean$latitude <- gsub(".", "", imoveis$latitude, fixed = TRUE) %>%
  sub("(\\d{2})", "\\1\\.", .) %>% 
  as.numeric()

# price_by_sqm
imoveis_clean$price_by_sqm <- as.numeric(imoveis_clean$price_by_sqm)

# condominium_fee e iptu
imoveis_clean$condominium_fee <- str_replace_all(imoveis$condominium_fee, 'R\\$', '') %>% 
  str_replace_all('[:punct:]', '') %>% 
  as.numeric()

imoveis_clean$iptu <- str_replace_all(imoveis$iptu, 'R\\$', '') %>% 
  str_replace_all('[:punct:]', '') %>% 
  as.numeric()

# visualizacao do novo df
glimpse(imoveis_clean)
summary(imoveis_clean)
```


## Etapa 3 - Análise Exploratória dos Dados

Com a preparacao dos dados concluída, pode-se prosseguir à análise exploratória. Para tal objetivo, procederemos a uma série de visualizações para ilustrar melhor a relação entre a variável de interesse em relação as demais.


```{r EDA 1}
## Visualizacao interativa
library(leaflet)

leaflet(data = imoveis_clean) %>% addTiles() %>% 
  addMarkers(~longitude, ~latitude, popup = ~as.character(property_d), 
             clusterOptions = markerClusterOptions()
  )

```


A começar com uma visualização interativa dos imóveis no mapa da cidade, através do pacote leaflet, consegue-se obersvar uma série de 20 coordenadas geográficas distantes da maioria das observações, configurando um ponto de interesse para se analisar com mais calma em seguida.


```{r EDA 2}
# visualizacao das variaveis continuas
library(ggplot2)

cont_vars <- c('area', 'iptu','condominium_fee')
plots_cont <- list()
for (var in cont_vars) {
  plots_cont[[var]] <- ggplot(imoveis_clean, aes_string(log(imoveis_clean[[var]]), log(imoveis_clean[['price']]))) + 
    geom_point() +
    geom_smooth(method = lm, se = F) + 
    ggtitle(paste(var, 'x price')) +
    theme_minimal()
  print(plots_cont[[var]])
}
```


Com o auxílio do pacote ggplot2, pode-se vislumbrar a relação gráfica entre as variáveis contínuas do dataframe. É interessante notar a ocorrência de outliers na relação entre 'price', 'area' e 'condominium_fee', gerando outras observações a serem olhadas mais de perto.


```{r EDA 3}
# visualizacao das variaveis factor
fact_vars <- c('bairro', 'rooms', 'bathrooms','garage')
plots_fact <- list()
for (var in fact_vars) {
  plots_fact[[var]] <- ggplot(imoveis_clean, aes_string(x = as.factor(imoveis_clean[[var]]), log(imoveis_clean[['price']]))) +
    geom_boxplot() + 
    ggtitle(paste(var, 'x price')) +
    theme_minimal()
  print(plots_fact[[var]])
}

plots_fact_c <- list()
for (var in fact_vars) {
  plots_fact_c[[var]] <- ggplot(imoveis_clean, aes_string(x = as.factor(imoveis_clean[[var]]))) + 
    geom_bar(stat = 'count') +
    ggtitle(paste('Total Observations in ',var)) +
    theme_minimal()
  print(plots_fact_c[[var]])
}
```


Por fim toma-se nota das relações entre as variáveis categóricas com auxílio do boxplots e gráficos de barra. Praticamente, todas as variáveis possuem algum outlier interessante, ou poucas observações de valores muito elevados, assim se fará uma sensível análise caso a caso para entender melhor suas particularidades. Outro ponto importante é a inexistência de outros bairros a não ser Vila Nova Conceição.


## Etapa 4 - Outliers

Nesta seção, realizaremos um breve estudo dos outliers identificados ao longo da análise exploratória para melhor entender seus aparecimentos.


```{r outliers}
## Investigacao outliers
imoveis_clean %>% filter(log(area) > 10 | log(price) < 10 | log(condominium_fee) > 10)
imoveis_clean %>% filter(bathrooms == 54)

# outliers de area e price: informações muito discrepantes em relação à realidade. Provavelmente, erros de digitação
imoveis_clean$area[which(imoveis$area == 30700)] <- NA
imoveis_clean <- imoveis_clean %>% filter(!(price == 18000))
imoveis_clean$condominium_fee[which(imoveis$condominium_fee == 460000)] <- NA

# o apartamento com mais de 54 banheiros parece muito fora da media em relacao ao seu preco e area
imoveis_clean$bathrooms[which(imoveis$bathrooms == 54)] <- NA

```


Os valores de 'price', 'area' e 'condominium_fee', assim como vizualizados acima, estavam muito discrepantes da realidade sem motivo aparente, dando uma boa evidência de serem erros de digitação. Por não haver forma melhor de checar sua veracidade, e para não gerar viés indesejado na análise, optei por retirá-los da amostra. Como o único imóvel com um número muito acima da média de banheiros não seguia outros em relação a área e valor, optei pela mesma abordagem também.


## Etapa 5 - Engenharia de Variáveis

Para a construção de um modelo de precificação eficiente, tem-se de extrair o máximo de informação de cada uma das variáveis e, ao mesmo tempo, evitar o overfitting, portanto a construção de novas variáveis é um passo fundamental da análise.

A começar por features já existentes, faz-se a agregação de algumas variáveis categóricas com o intuito de diminuir classes com pouca representatividade na amostra como visto nos gráficos de barra. A ideia é evitar, além do overfitting, possíveis bugs na separação nos dados de treino e teste.


```{r FE1}
# agregação dos valores para não causar overfitting pela baixa quantidade de valores
roomsBathGarage <- imoveis_clean %>% 
  select(c(rooms, bathrooms, garage)) %>% 
  mutate(rooms_coerc = ifelse(rooms > 4, 4, rooms),
         bathrooms_coerc = ifelse(bathrooms > 6, 6, bathrooms),
         garage_coerc = ifelse(garage > 5, 5, garage))
```


Como as variáveis de identificação, em seu estado bruto, não são relevantes à análise, executarei a construção de outras com possibilidade maior de fornecer informação. Após realizar sua criação, faço plots demonstrando suas informações em relação às variáveis antigas.


```{r FE2}
# criacao dos dfs comas supostas novas variaveis de interesse
imoveis_clean_rua <- imoveis_clean %>% 
  group_by(rua) %>%
  summarise(total_a = n(),
            media_p = mean(price_by_sqm, na.rm = T)) %>%
  filter(!(is.na(rua)))

imoveis_clean_condominio <- imoveis_clean %>% 
  group_by(condominio) %>%
  summarise(total_a = n(),
            media_p = mean(price_by_sqm, na.rm = T)) %>%
  filter(!(is.na(condominio))) 

# como ha agencias sem nenhuma entrada, filtro antes de achar as variaves finais
imoveis_clean_agent <- imoveis_clean %>% 
  group_by(agent) %>%
  summarise(total_a = n(),
            media_p = mean(price_by_sqm, na.rm = T)) %>%
  filter(!(is.na(agent))) %>% 
  filter(!(is.na(media_p))) 

# plot total_a
var_t <- list(imoveis_clean_rua %>% arrange(desc(total_a)), 
              imoveis_clean_condominio %>% arrange(desc(total_a)), 
              imoveis_clean_agent %>% arrange(desc(total_a)))

plots_total <- list()

for (i in 1:length(var_t)){
  plots_total[[i]] <- ggplot(var_t[[i]], aes(x = factor(var_t[[i]][[1]], levels = var_t[[i]][[1]]), 
                                             y = total_a)) + 
    geom_bar(stat="identity", width=.5) +
    coord_flip() +
    labs(title=paste('Anúncios x ', names(var_t[[i]])[[1]]), 
         x = names(names(var_t[[i]])[[1]]),
         y = 'Anúncios') 
  
  print(plots_total[[i]])
}

# plot da media_p 
var_m <- list(imoveis_clean_rua %>% arrange(desc(media_p)), 
              imoveis_clean_condominio %>% arrange(desc(media_p)), 
              imoveis_clean_agent %>% arrange(desc(media_p)))

plots_media <- list()

for (i in 1:length(var_m)){
  plots_media[[i]] <- ggplot(var_m[[i]], aes(x = factor(var_m[[i]][[1]], levels = var_m[[i]][[1]]), 
                                             y = media_p)) + 
    geom_bar(stat="identity", width=.5) +
    coord_flip() +
    labs(title=paste('Media x ', names(var_m[[i]])[[1]]), 
         x = names(names(var_m[[i]])[[1]]),
         y = 'Media') 
  
  print(plots_media[[i]])
}

# variaveis criadas
vars_rua <- imoveis_clean_rua %>% select(rua, anuncio_rua = total_a, valores_rua = media_p) 
vars_condo <- imoveis_clean_condominio %>% select(condominio, anuncio_condo = total_a, valores_condo = media_p)  
vars_agente <- imoveis_clean_agent %>% select(agent, anuncio_agente = total_a, valores_agente = media_p) 
```


## Etapa 5 - Dataframe Final para Análise
 
Após terminar a construção de novas variáveis, prossegue-se às etapas de criação do modelo preditivo: excluir variáveis não relevantes, realizar as etapas de pré processamento e, por fim, executar a análise preditiva. Para iniciar o trabalho, começarei pela junção das novas variáveis e exclusão das identificadoras, além de 'bairro' que, como visto ao longo de toda análise exploratória, possui variância muito baixa.


```{r seleção}
# df final para analise e com variaveis novas
imoveis_final <- imoveis_clean %>%
  left_join(roomsBathGarage) %>% 
  left_join(vars_rua) %>% 
  left_join(vars_condo) %>% 
  left_join(vars_agente) %>% 
  select(-c(Data, rua, numero, bairro, price_by_sqm, condominio, rooms, bathrooms, garage,agent, agent_number, 
            latitude, longitude, property_d, url))
  
glimpse(imoveis_final)
```
 

Em seguida, prosseguir-se-á à separação dos dados em set de treino e teste. É sempre recomendável realizar essa ação antes de se executar qualquer trabalho preditivo para evitar qualquer tipo de viés de seleção. Ao longo de toda esta etapa, faremos uso do pacote de Machine Learnig Caret e seus componentes auxiliares como o mlbench. Também, vale ressaltar a criação de uma função que transforma, de forma automática, variáveis do tipo numeric a factor. 


```{r train test}

library(caret)
library(mlbench)
set.seed(666)

sample <- createDataPartition(imoveis_final$price, times = 1, list = F, p = .8)
train_sample <- imoveis_final[sample, ]
test_sample <- imoveis_final[-sample, ]

# funcao para transformar variaveis em fact
toFactor <- function(df, features) {
  for (feature in features) {
    df[[feature]] <- factor(df[[feature]], exclude = NULL)
  }
  return(df)
}

fact_vars_final <- c('rooms', 'bathrooms','garage')
train_fact <- toFactor(train_sample, fact_vars_final)
test_fact <- toFactor(test_sample, fact_vars_final)
```


## Etapa 6 - Modelo Preditivo


Chega-se à parte mais relevante do trabalho: construção do modelo preditivo linear para precificação de imóveis. Para se alcançar o objetivo, faz-se o pré processamento dos dados, estudo da importância das variáveis e obtenção do melhor modelo linear.

A primeira etapa consistirá na preparação dos dados através da padronização das variáveis contínuas, e o tratamento dos valores NA. Como há muita informação com algum valor faltante e não há a possibilidade de determinar o motivo de seus não aparecimentos, procederei com um método de imputação a partir do algorítmo de KNN. Logo em seguida, parte-se à contrução do primeiro modelo e à análise das variáveis mais importantes. Vale resaltar no uso do parâmetro de controle, com a escolha da 10 validações cruzadas, com o intuito de eliminar ainda mais riscos de overfitting dos parâmetros.



```{r preProcess}
# Pré processadores
preprocessParams_train <- preProcess(train_fact, method=c("knnImpute", "center", "scale"))
preprocessParams_test <- preProcess(test_fact, method=c("knnImpute", "center", "scale"))

# Dfs transformados
train_preproc <- predict(preprocessParams_train, train_fact)
test_preproc <- predict(preprocessParams_test, test_fact)

```


Com os dataframes prontos para análise, a próxima etapa será o rankiamento das melhores variáveis do modelo, quanto é a importância de cada uma para melhorar a eficácia e quais devem ou não ser eliminadas ao final. Para isso, usa-se o método de eliminação recursiva. Abaixo, consegue se observar como cada variável agrega ao modelo e quais as mais importantes.


```{r rfe}
# RFE
control_rfe <- rfeControl(functions=lmFuncs, method="cv", number=10)
results <- rfe(price ~ ., data = train_preproc, sizes=c(1:15), rfeControl=control_rfe)
varImp(results, scale=FALSE)
plot(results, type=c("g", "o"))
```

Assim como visto acima, mesmo com o alto número de variáveis, todas contribuem de forma positiva para a melhorar acurácia do modelo, além de que a 2a variável mais importante foi a construída 'valores_condo', portanto o algorítmo sugere o uso de todas as variáveis para o melhor resultado possível. Para fins de comparação e certificação, 2 modelos serão construídos: um com as variáveis originais, e outro com criadas. Ambas serão comparadas na performance com os dados de treino e teste, além de usarem o mesmo número de validações cruzadas (FALTOU COLOCAR VALIDAÇÕES CRUZADAS IGUAIS COM ÍNDICE)

```{r modelos e score}
# Comparação entre modelo com features originais x  + criadas

# Controle para todos os modelos
control <- trainControl(method="cv", number=10)

# modelo com as originais
model1 <- train(price ~ 
                  area +
                  condominium_fee +
                  iptu +
                  rooms_coerc +
                  bathrooms_coerc +
                  garage_coerc,
                data = train_preproc,
                method = "lm",
                trControl = control,
                metric = 'RMSE')

# modelo com as features criadas
model2 <- train(price ~ .,
                  data = train_preproc,
                  method = "lm",
                  trControl = control,
                  metric = 'RMSE')

# Comparação gráfica dos 2 modelos
model_list <- list(Originais = model1, Originais_eNovas = model2)
resamples <- resamples(model_list)
dotplot(resamples, metric = 'RMSE')

# score dos modelos
pred1 <- predict(model1, test_preproc)
pred2 <- predict(model2, test_preproc)

test_Score1 <-data.frame(obs = test_preproc$price, pred= pred1)
test_Score2 <-data.frame(obs = test_preproc$price, pred= pred2)

defaultSummary(test_Score1)
defaultSummary(test_Score2)
```


## FIM